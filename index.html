<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>HonoursJournal by jctwood</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>HonoursJournal</h1>
        <p>Adaptive user interfaces for motion controlled virtual reality</p>

        <p class="view"><a href="https://github.com/jctwood/honours">View the Project on GitHub <small>jctwood/honours</small></a></p>


        <ul>
          <li><a href="https://github.com/jctwood/honours/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/jctwood/honours/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/jctwood/honours">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h3>
<a id="160916-hello-world" class="anchor" href="#160916-hello-world" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>16/09/16</em> Hello World</h3>

<p>After listening to the various pieces of advice given to us I decided the best way to find a topic for my proposal would be to find a problem I would enjoy researching and solving. Having closely followed developments in Virtual Reality over the past years I know that user interfaces still have many issues associated with them. When using any controller with positional tracking it is harder to design a single interface for every user, due to different heights, arm lengths and dexterity. Thus my preliminary concept for a topic is to make a user interface back end that can easily adapt and intelligently evolve based on the user.</p>

<h3>
<a id="260916-research" class="anchor" href="#260916-research" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>26/09/16</em> Research</h3>

<p>I spent a good few days trawling through ACM and the library search uncovering various books along with the conference, IUI (Intelligent User Interfaces). I contacted the professor who runs the conference to request the location of the previous papers and was pleasantly surprised to receive a quick reply directing me toward the proceedings of the last 21 conferences. I also began doing some user research (probably not the term) by borrowing the key to the HIVE in Abertay which is filled with various virtual reality headsets. The next step is to start finding literature that lends itself to the implementation of my project. In the back of my head I have been considering the various platforms I could use and frameworks. I would really like to avoid using an existing game engine as my project application will not need much more than a renderer to function. I am starting to lean toward implementing a Virtual Reality camera for the Game Education Framework.</p>

<h3>
<a id="021016-refining-the-topic" class="anchor" href="#021016-refining-the-topic" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>02/10/16</em> Refining the Topic</h3>

<p>I had a small scare when speaking with a lecturer about my topic about the validity of my research question as a technical problem. Fortunately this was resolved when I further discussed the details of my proposal and although I have not posed a technical problem it will certainly have a technical solution. I have also altered my topic to cover Adaptive User Interfaces for Motion Controlled Virtual Reality as opposed to Adaptive and Intelligent User Interfaces. This is because Adaptive User Interfaces could be applied more readily for short user sessions whereas an intelligent user interface would require a number of longer sessions. After more research there seem to be two main 'semantics' when it comes to adaptivity for user interfaces, static and dynamic. Static adaptivity focuses on updating and optimising the user experience between sessions while dynamic uses techniques to continuously adjust the interface for the user. </p>

<p>After speaking with a lecturer I am starting to consider implementing my application in Unreal Engine or Unity but obviously focusing on the programming of the user interface and avoiding their systems for implementing such things. They persuaded me that this would allow more focus on the development of the adaptivity. The Playstation VR headset available for research purposes would allow me to develop for motion controlled virtual reality without competing with the many 3rd year group projects using the Vive (the other motion controlled VR platform available to us). I also emailed someone at Oculus about the potential of an Oculus Touch developer kit but have not heard back. The next step is to begin setting up a project and pipeline for Unity/Unreal and the PSVR and work out how I can develop an application without the constant need for the headset as it will be shared and I may not always have access.</p>

<h3>
<a id="061016-evaluating-existing-interfaces" class="anchor" href="#061016-evaluating-existing-interfaces" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>06/10/16</em> Evaluating existing interfaces</h3>

<p>I spent a few hours exploring the various interfaces of the available Vive games on the University's machine. I noted some interesting features. Almost every game uses highlighting to display when something will be interacted with. This creates a fairly robust sense of responsiveness when quickly performing tasks. However when many items are selectable the highlighted object isn't always the obvious one at least in Fantastic Contraption and Valve's The Lab. Another point of interest was that the majority of my errors were made when trying to pick things up from the floor or on surfaces. Although it seems counter-intuitive the interfaces hovering in the air which don't really have a real world reference are consistently easier to use. Although it does become tiring using elevated interfaces.</p>

<p>Most of the experiences utilised only one button on the controller outside of very specific circumstances in which the controller changed to suit the interaction, i.e. the touchpad became a scroll wheel in VR to display that interacting would scroll the visible text. I thought thoroughly about how to execute the practical side of the project as well as the evaluation aspect. By creating an iteration of an interface which can then be evaluated through testing seems like the obvious choice. The first iteration would be a typical 2D interface like many of the menus found in VR games. The second iteration would be a 3D interface which utilises static adaptivity. i.e. will adapt during transition sequences like going back or forward through a menu. The final iteration would use dynamic adaptivity to create a continuously adjusting environment to accommodate as best as possible to the user.</p>

<p>The evaluation would be done by presenting the user with the three environments asking them to perform a series of interactions and then evaluate how usable the interfaces were. This would most likely also ask them to evaluate how much error they made using the interfaces. As well as having quality testing I plan to implement quantitative testing by gathering data on how many times attempted interactions fail or are undone. This should provide a good idea of how well the adaptive elements of the program affect the usability.</p>

<h3>
<a id="171016-continuing-evaluation-and-preparing-application" class="anchor" href="#171016-continuing-evaluation-and-preparing-application" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>17/10/16</em> Continuing evaluation and preparing application</h3>

<p>I created a timetable toward the end of last week outlining what I want to try and achieve each week until week 14. Currently I plan to complete two readings a week and a section of my proposal every two weeks. Alongside this i will begin creating a feasibility demo and continue evaluating other applications. Today I spent a few hours analysing interfaces within other applications. Most had little to no interaction, with gaze being the primary input method. The ones that did not use locomotion were by far the most comfortable while any that tried to implement non teleportation based locomotion made me feel unease within seconds.</p>

<p>I used the Playstation VR which I was extremely impressed by. The visuals were incredibly smooth and seemed higher fidelity than those of the Vive. The tracking worked well although I did not use the move controllers. Unfortunately the design of the applications I played let it down hugely with all but one relying on translation based movement using a controller. Having thought often about my research question I am beginning to think I should focus not only on the concept of adaptive user interfaces but also on the systems that gather data to support those interfaces i.e. Error Analysis and Pattern Recognition.</p>

<h3>
<a id="181016-notes-on-adaptivity" class="anchor" href="#181016-notes-on-adaptivity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>18/10/16</em> Notes on adaptivity</h3>

<p>Reading through the paper "Error-based Adaptive User Interfaces" which focuses on making 2D touch interfaces more accessible I came across some terminology to describe ideas I have been developing. First of all the concept of a 'reversal', which is defined as "the act of a user where he/she taps on a component and “quickly” reverses the action". I can imagine these types of errors being very easy to detect and utilise. The paper also mentions the idea of user models, trying to understand how the user interacts with the interface and using that to adapt it.</p>

<p>I also set up a project for the Vive in Unreal Engine 4 which was a very smooth process aside from some issues aligning the world floor with the real floor. I am still thinking about what complex interface I can use to demo my research. I think it needs to be something with simple interactions that utilises 3D space and encourages quick use. Maybe some kind of RTS interface would be interesting, could do some simple steering type mechanisms.</p>

<h3>
<a id="191016-continued-notes" class="anchor" href="#191016-continued-notes" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>19/10/16</em> Continued notes...</h3>

<p>The paper "Plasticity in 3D User Interfaces" goes into some detail about the different categories of plastic user interfaces i.e. those which can be modified/modify themselves. The table below defines adaptive user interfaces as those which are adapted by the system at runtime. This is inline with the use of error-analysis which by necessity is by the system at runtime.
<img src="http://i.imgur.com/c4Bsnup.png" alt="Table"></p>

<p>Later in the paper it discusses the types of interactivity in 3D worlds, breaking it into 3 modes of interaction: 'object manipulation, navigation and application control'. To begin building adaptive interfaces these interactions will need to be further separated into the intentions of the user. Object manipulation could consist of transformation (i.e. movement, rotation), interaction (verbs i.e. taking, using, dropping) and perhaps meta tasks such as storing in an inventory, examining, deleting. Navigation can be broken into translation and rotation or looking. Application Control could be any manner of things but probably simplifies to user interface interaction like highlighting, selecting and undoing. By taking these individual components of user interaction and finding their points of weakness I can begin deciding how adaptation could benefit them. One example that comes to mind is when a user wants to take an object that is in 3D space but it is distant and they keep making errors. By using the context of that action the system can make an educated guess at what the user wanted to do and then suggest or execute that. The system could look at what the closest object during the failed interaction was or what the user was looking at during the interaction, it could even use previous data of patterns in interaction to predict the intended action.</p>

<h3>
<a id="211016-abstract-draft" class="anchor" href="#211016-abstract-draft" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>21/10/16</em> Abstract Draft</h3>

<p>Virtual reality allows for intuitive 3D interaction using head and hand tracking. However many traditional 2D interfaces become awkward and cumbersome when translated to virtual reality (VR). This is due to the combination of fine input afforded by motion controls and the extra degrees of movement native to 3D space. One possible way to retain the usability of these interfaces is to have them adapt as they are interacted with. This paper seeks to explore the implementation of adaptive user interfaces in VR and assess their effect on usability. By using error analysis and pattern recognition the interface could try to predict or suggest actions the user may be trying to perform. Two iterations of a 3D interface, one with adaptation, will be used to compare the usability in various ways. The result of this comparison should demonstrate the benefit of adaptive user interfaces for virtual reality. If so then complex tasks currently relegated to 2D interfaces could be brought into the intuitive world of VR.</p>

<h3>
<a id="251016-presentation" class="anchor" href="#251016-presentation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>25/10/16</em> Presentation</h3>

<p>Completed my presentation to the class and received some interesting questions. Mostly on whether the adaptation would take place dynamically at run time and if so how does that affect a new user's ability to learn the interface. It is something I will have to consider during development. I meet my supervisor later today so will try and get through at least the first half of my proposal draft if not more. Also discovered that the abstract needs to be structured, i.e. separated into its components, context, aim etc. Managed to get down the beginnings of my proposal, introduction and context. It is really helping me solidify the thoughts in my head and hopefully once it is finished I can use the iterations to begin refining the techniques I wish to employ.</p>

<p>I have just finished the first draft of my proposal. Although it is incoherent at times it has outlined which areas I need to research more particularly the techniques and methodology of how I will go about implementing the interfaces. I need to make my template interface very concrete and feasible with the techniques for adaptive ui nailed down. A few more references out with adaptive ui would be useful and help support the context. Currently I speak too much about the background of general ui rather than the background of specifically adaptive ui.</p>

<p>About to have my first meetings with my supervisor so hopefully I will glean some action to take for the next week. It is definitely possible that by the end of this week I can have something polished up that I'd be happy to submit. As they say the first step is always the hardest. I also plan to have my other module's coursework in a state which I can be happy with. It should provide some much needed rest between bouts of writing and research.</p>

<h3>
<a id="271016-research-on-vr-ui" class="anchor" href="#271016-research-on-vr-ui" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>27/10/16</em> Research on VR UI</h3>

<p>Having finished my first draft I decided to go back and research the areas I could not back up. These were mainly usability and ux design in VR. I found some really great resources including a Valve GDC talk which led me to Fitt's law about speed of pointer use in correlation to size of target. This really supports my view that adding a third dimension can make navigation more challenging at a distance. I also found a research paper concluding that 3D tracked controllers are no more fatiguing than using a mouse to navigate 3D environments. I made many notes and am about to rewrite my proposal before passing it on to my supervisor for corrections.</p>

<h3>
<a id="021116-proposal" class="anchor" href="#021116-proposal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>02/11/16</em> Proposal</h3>

<p>Over the weekend I polished my proposal and sent it to my supervisor. Their feedback focused on adding visual representations of harder to grasp concepts. I used the 3D colour palette from tilt brush and the 2D colour palette in unreal engine 4. I would still like to find some diagram of interactions to show how a 3D interface could be seen as more intuitive than a 2D counterpart. We were also given more detailed information about the feasibility demos which we need to have 3 'artefacts' for. Currently I plan to have a design document outlining the components of the interface, a basic version of the analytics used to gather quantitative data and the interface itself in unreal engine 4. Today I plan to create a schedule for the next few months which I can include in the proposal.</p>

<h3>
<a id="071116-submission" class="anchor" href="#071116-submission" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>07/11/16</em> Submission</h3>

<p>I spent today finalising the references in my proposal and expanding on the summary and evaluation. It will be a relief to have submitted it tonight and start working on the implementation for the feasibility demo the rest of the week. </p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/jctwood">jctwood</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
